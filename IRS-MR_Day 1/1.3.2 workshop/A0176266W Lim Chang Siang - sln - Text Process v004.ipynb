{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Workshop] Textual Knowledge Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ws_img_001.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Package Installation (one time job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download() # Select and Download the \"popular\" from \"Collections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_casing(sentence):\n",
    "    # Quiz: How to implement this function without using str.lower()?\n",
    "    new_sentence = sentence.lower()\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Abbreviation expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_abbriviation(sentence):\n",
    "    replacement_patterns = [\n",
    "        (r'won\\'t', 'will not'),\n",
    "        (r'can\\'t', 'cannot'),\n",
    "        (r'i\\'m', 'i am'),\n",
    "        (r'ain\\'t', 'is not'),\n",
    "        (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "        (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "        (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "        (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "        (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "        (r'(\\w+)\\'d', '\\g<1> would')]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n",
    "\n",
    "    new_sentence = sentence\n",
    "    for (pattern, repl) in patterns:\n",
    "        (new_sentence, count) = re.subn(pattern, repl, new_sentence)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Punctuation removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_removal(sentence):\n",
    "    # Remove the all the punctuations except '\n",
    "    new_sentence = re.sub(',|!|\\?|\\\"|<|>|\\(|\\)|\\[|\\]|\\{|\\}|@|#|\\+|\\=|\\-|\\_|~|\\&|\\*|\\^|%|\\||\\$|/|`|\\.|\\'',\n",
    "                          '', sentence,count=0, flags=0)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(sentence):\n",
    "    new_sentence = nltk.word_tokenize(sentence)\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopword_removal(sentence):\n",
    "    #stoplist = stopwords.words('english')\n",
    "     \n",
    "    with open('./stopwords.txt') as file:\n",
    "        stoplist = [stopword.replace('\\n', '').lower() for stopword in file.readlines()]\n",
    "    \n",
    "    new_sentence = [word for word in sentence if word not in stoplist]\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    pack = nltk.pos_tag([word])\n",
    "    tag = pack[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def lemmatization(sentence):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    new_sentence = [lemmatizer.lemmatize(word, get_wordnet_pos(word) or wordnet.NOUN) for word in sentence]\n",
    "\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Spelling correction (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qw/0ndgh2td1pqcpvynxn4fkwch0000gn/T/ipykernel_2254/205888429.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'I'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'met'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'my'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frienss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yesterdsy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspell_correction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/qw/0ndgh2td1pqcpvynxn4fkwch0000gn/T/ipykernel_2254/205888429.py\u001b[0m in \u001b[0;36mspell_correction\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mnew_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrection_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m##############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Package may be used in this section\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Spell correction is also important in text preprocessing.\n",
    "# Please refer to the Day2 slides and see how jaccard_distance works\n",
    "def spell_correction(sentence):\n",
    "    new_sentence = sentence\n",
    "    ##############################\n",
    "    # Your code here\n",
    "    correct_words = words.words()\n",
    "    for index, w in enumerate(sentence):\n",
    "        correction_list = {}\n",
    "        for word in correct_words:\n",
    "            if(w[0] == word[0] and len(w) > 2 and len(word) > 2):\n",
    "                jd = jaccard_distance(set(ngrams(w, 3)), set(ngrams(word, 3)))\n",
    "                if(jd < 0.15):\n",
    "                    correction_list[word] = jd\n",
    "            else:\n",
    "                correction_list[word] = 0.0\n",
    "        if(len(correction_list) > 1):\n",
    "            correction_list = {k: v for k, v in sorted(correction_list.items(), key = lambda item: item[1])}\n",
    "        for correction in correction_list:\n",
    "            if(correction == w):\n",
    "                new_sentence[index] = w\n",
    "                break\n",
    "            else:\n",
    "                new_sentence[index] = list(correction_list)[0]\n",
    "    ############################## \n",
    "    return new_sentence\n",
    "\n",
    "# example\n",
    "s = ['I', 'met', 'my', 'boy', 'frienss', 'yesterdsy']\n",
    "print(spell_correction(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "jaccard_distance(set(ngrams(\"frien\", 1)), set(ngrams(\"friend\", 1)))\n",
    "#print(set(ngrams(\"friens\", 4)))\n",
    "#print(set(ngrams(\"friend\", 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Integrate all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(raw_sentence):\n",
    "    sentence = lower_casing(raw_sentence)\n",
    "    sentence = expand_abbriviation(sentence)\n",
    "    sentence = punctuation_removal(sentence)\n",
    "    sentence = tokenization(sentence)\n",
    "    sentence = stopword_removal(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    sentence = spell_correction(sentence) # Spelling check\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lets have a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eat', '100', 'hamburger', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "# A Common text pre-processing procedure is as follow:\n",
    "# Raw text -> Lower casing -> Expand abbr -> Punctuation removal->...\n",
    "# ... -> Tokenization  -> Stop word removal -> Lemmatization\n",
    "# All the functions are defined in above code blocks. Please feel free to go through it\n",
    "# and change some of the codes.\n",
    "\n",
    "# Let's assume we have a raw sentence.\n",
    "raw_sentence = 'He said, \"we\\'d have eaten more than 100 hamburgers from yesterdsy.\"'\n",
    "\n",
    "# Can you guess the result of procedure?\n",
    "sentence = text_preprocessing(raw_sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eat', '100', 'hamburger', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "# Or if we only want to use some of the preprocessing techniques, we can call the function separately.\n",
    "sentence = lower_casing(raw_sentence)\n",
    "sentence = punctuation_removal(sentence)\n",
    "sentence = expand_abbriviation(sentence)\n",
    "sentence = tokenization(sentence)\n",
    "sentence = stopword_removal(sentence)\n",
    "sentence = lemmatization(sentence)\n",
    "sentence = spell_correction(sentence) # Spelling check\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hello\n",
      "1 []\n",
      "\n",
      "2 Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n",
      "2 ['asd', 'knowledge', 'bot', 'feel', 'free', 'autism', 'spectrum', 'disorder', 'asd']\n",
      "\n",
      "3 What is definition of Autistic Spectrum Disorder?\n",
      "3 ['definition', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "4 Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n",
      "4 ['autism', 'autism', 'spectrum', 'disorder', 'asd', 'refers', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'center', 'disease', 'control', 'autism', 'estimate', '1', '54', 'child', 'united']\n",
      "\n",
      "5 What are the symptoms of Autistic Spectrum Disorder?\n",
      "5 ['symptom', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "6 Making little or inconsistent eye contact. \n",
      "6 ['inconsistent', 'eye', 'contact']\n",
      "\n",
      "7 Tending not to look at or listen to people.\n",
      "7 ['tend', 'not', 'listen', 'people']\n",
      "\n",
      "8 Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n",
      "8 ['rarely', 'share', 'enjoyment', 'object', 'activity']\n",
      "\n",
      "9 Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n",
      "9 ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n",
      "\n",
      "10 Having difficulties with the back and forth of conversation.\n",
      "10 ['difficulty', 'conversation']\n",
      "\n",
      "11 Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n",
      "11 ['talk', 'length', 'favorite', 'subject', 'notice', 'not', 'chance', 'respond']\n",
      "\n",
      "12 Having facial expressions, movements, and gestures that do not match what is being said.\n",
      "12 ['facial', 'expression', 'movement', 'gesture', 'not', 'match']\n",
      "\n",
      "13 Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n",
      "13 ['unusual', 'tone', 'voice', 'sound', 'singsong', 'flat', 'robotlike']\n",
      "\n",
      "14 Having trouble understanding another person’s point of view or being unable to predict or understand other people’s actions.\n",
      "14 ['trouble', 'understand', 'person', '’', 'view', 'unable', 'predict', 'understand', 'people', '’', 'action']\n",
      "\n",
      "15 Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n",
      "15 ['repeat', 'behavior', 'unusual', 'behavior', 'repeat', 'phrase', 'behavior', 'call', 'echolalia']\n",
      "\n",
      "16 Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n",
      "16 ['last', 'intense', 'topic', 'detail']\n",
      "\n",
      "17 Having overly focused interests, such as with moving objects or parts of objects.\n",
      "17 ['overly', 'focus', 'move', 'object', 'object']\n",
      "\n",
      "18 Getting upset by slight changes in a routine.\n",
      "18 ['upset', 'slight', 'routine']\n",
      "\n",
      "19 Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n",
      "19 ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n",
      "\n",
      "20 People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n",
      "20 ['people', 'asd', 'experience', 'sleep', 'irritability', 'people', 'asd', 'experience', 'challenge', 'strength', 'include', ':']\n",
      "\n",
      "21 Being able to learn things in detail and remember information for long periods of time.\n",
      "21 ['learn', 'detail', 'remember', 'period', 'time']\n",
      "\n",
      "22 Being strong visual and auditory learners.\n",
      "22 ['strong', 'visual', 'auditory', 'learner']\n",
      "\n",
      "23 Excelling in math, science, music, or art.\n",
      "23 ['excel', 'math', 'science', 'music', 'art']\n",
      "\n",
      "24 What should I do if I got diagnosis the Autistic Spectrum Disorder?\n",
      "24 ['diagnosis', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "25 Consult a doctor and psychologist for early intervention programs.\n",
      "25 ['consult', 'doctor', 'psychologist', 'intervention', 'program']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In the workshop folder, we have a database called questionbase_raw.txt. Try to import the txt file\n",
    "# into the Python and do the preprocessing for all the sentence. See what will happen!\n",
    "\n",
    "with open('./questionbase_raw.txt') as file:\n",
    "    raw_sentences = [sentence.replace('\\n', '') for sentence in file.readlines()]\n",
    "\n",
    "i = 1\n",
    "for raw_sentence in raw_sentences:\n",
    "    processed_sentence = text_preprocessing(raw_sentence)\n",
    "    if raw_sentence != 'Q' and raw_sentence != 'A':\n",
    "        print(i, raw_sentence)\n",
    "        print(i, processed_sentence)\n",
    "        i += 1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Preprocessing [Workshop]\n",
    "### Spacy (Python package) is modern and powerful NLP tool. \n",
    "### You can use spacy functions do most of the preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nlp tool\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Raw sentence\n",
    "raw_sentence = 'He said, \"we\\'d have eaten more than 100 hamburgers from yesterdsy.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He he PRON PRP nsubj Xx True True\n",
      "said say VERB VBD ROOT xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "\" \" PUNCT `` punct \" False False\n",
      "we we PRON PRP nsubj xx True True\n",
      "'d would AUX MD aux 'x False True\n",
      "have have AUX VB aux xxxx True True\n",
      "eaten eat VERB VBN ccomp xxxx True False\n",
      "more more ADJ JJR amod xxxx True True\n",
      "than than ADP IN quantmod xxxx True True\n",
      "100 100 NUM CD nummod ddd False False\n",
      "hamburgers hamburger NOUN NNS dobj xxxx True False\n",
      "from from ADP IN prep xxxx True True\n",
      "yesterdsy yesterdsy PROPN NNP pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "\" \" PUNCT '' punct \" False False\n"
     ]
    }
   ],
   "source": [
    "# Use SpaCy nlp tool to process the raw sentence\n",
    "token_sentence = nlp(raw_sentence)\n",
    "for token in token_sentence:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sentence[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRON'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_sentence[0].pos_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your hands-on time now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used the given information to implement your own text preprocessing\n",
    "def my_preprocessing(raw_sentence, nlp_tool):\n",
    "    token_sentence = nlp_tool(raw_sentence) # nlp model return tokenization words\n",
    "    preprocessed_sentence = None\n",
    "    \n",
    "    #########################\n",
    "    # Your code here\n",
    "    # You should ignore the abbreviation expanding part here since those abbr words\n",
    "    # are identified as stop words in spacy.\n",
    "    #\n",
    "    # But also consider how to process abbr like U.K. and US such words. \n",
    "    # (hint: word2vec, not mentioned in this course)\n",
    "    \n",
    "    processing_sentence = []\n",
    "    for token in token_sentence:\n",
    "        if(token.is_stop == False and token.pos_ != \"PUNCT\"): # Stop Word Removal and Removal of Punctuation\n",
    "            processing_sentence.append(token.lemma_) # return Lemmatization\n",
    "            \n",
    "    #########################\n",
    "    preprocessed_sentence = processing_sentence\n",
    "\n",
    "    return preprocessed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Hello\n",
      "1 =>> text prep output:\n",
      " ['hello']\n",
      "1 =>> my spacy  output:\n",
      " []\n",
      "\n",
      "2 Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n",
      "2 =>> text prep output:\n",
      " ['hello', 'asd', 'knowledge', 'bot', 'feel', 'free', 'ask', 'autism', 'spectrum', 'disorder', 'ASD']\n",
      "2 =>> my spacy  output:\n",
      " ['asd', 'knowledge', 'bot', 'feel', 'free', 'autism', 'spectrum', 'disorder', 'asd']\n",
      "\n",
      "3 What is definition of Autistic Spectrum Disorder?\n",
      "3 =>> text prep output:\n",
      " ['definition', 'Autistic', 'Spectrum', 'Disorder']\n",
      "3 =>> my spacy  output:\n",
      " ['definition', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "4 Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n",
      "4 =>> text prep output:\n",
      " ['autism', 'autism', 'spectrum', 'disorder', 'ASD', 'refer', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'accord', 'Centers', 'Disease', 'Control', 'autism', 'affect', 'estimate', '1', '54', 'child', 'United', 'States', 'today']\n",
      "4 =>> my spacy  output:\n",
      " ['autism', 'autism', 'spectrum', 'disorder', 'asd', 'refers', 'broad', 'range', 'condition', 'characterize', 'challenge', 'social', 'skill', 'repetitive', 'behavior', 'speech', 'nonverbal', 'communication', 'center', 'disease', 'control', 'autism', 'estimate', '1', '54', 'child', 'united']\n",
      "\n",
      "5 What are the symptoms of Autistic Spectrum Disorder?\n",
      "5 =>> text prep output:\n",
      " ['symptom', 'Autistic', 'Spectrum', 'Disorder']\n",
      "5 =>> my spacy  output:\n",
      " ['symptom', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "6 Making little or inconsistent eye contact. \n",
      "6 =>> text prep output:\n",
      " ['make', 'little', 'inconsistent', 'eye', 'contact']\n",
      "6 =>> my spacy  output:\n",
      " ['inconsistent', 'eye', 'contact']\n",
      "\n",
      "7 Tending not to look at or listen to people.\n",
      "7 =>> text prep output:\n",
      " ['tend', 'look', 'listen', 'people']\n",
      "7 =>> my spacy  output:\n",
      " ['tend', 'not', 'listen', 'people']\n",
      "\n",
      "8 Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n",
      "8 =>> text prep output:\n",
      " ['rarely', 'share', 'enjoyment', 'object', 'activity', 'point', 'show', 'thing']\n",
      "8 =>> my spacy  output:\n",
      " ['rarely', 'share', 'enjoyment', 'object', 'activity']\n",
      "\n",
      "9 Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n",
      "9 =>> text prep output:\n",
      " ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n",
      "9 =>> my spacy  output:\n",
      " ['fail', 'slow', 'respond', 'call', 'verbal', 'attempt', 'gain', 'attention']\n",
      "\n",
      "10 Having difficulties with the back and forth of conversation.\n",
      "10 =>> text prep output:\n",
      " ['have', 'difficulty', 'forth', 'conversation']\n",
      "10 =>> my spacy  output:\n",
      " ['difficulty', 'conversation']\n",
      "\n",
      "11 Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n",
      "11 =>> text prep output:\n",
      " ['talk', 'length', 'favorite', 'subject', 'notice', 'interested', 'give', 'chance', 'respond']\n",
      "11 =>> my spacy  output:\n",
      " ['talk', 'length', 'favorite', 'subject', 'notice', 'not', 'chance', 'respond']\n",
      "\n",
      "12 Having facial expressions, movements, and gestures that do not match what is being said.\n",
      "12 =>> text prep output:\n",
      " ['have', 'facial', 'expression', 'movement', 'gesture', 'match', 'say']\n",
      "12 =>> my spacy  output:\n",
      " ['facial', 'expression', 'movement', 'gesture', 'not', 'match']\n",
      "\n",
      "13 Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n",
      "13 =>> text prep output:\n",
      " ['have', 'unusual', 'tone', 'voice', 'sound', 'sing', 'song', 'flat', 'robot', 'like']\n",
      "13 =>> my spacy  output:\n",
      " ['unusual', 'tone', 'voice', 'sound', 'singsong', 'flat', 'robotlike']\n",
      "\n",
      "14 Having trouble understanding another person’s point of view or being unable to predict or understand other people’s actions.\n",
      "14 =>> text prep output:\n",
      " ['have', 'trouble', 'understand', 'person', 'point', 'view', 'unable', 'predict', 'understand', 'people', 'action']\n",
      "14 =>> my spacy  output:\n",
      " ['trouble', 'understand', 'person', '’', 'view', 'unable', 'predict', 'understand', 'people', '’', 'action']\n",
      "\n",
      "15 Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n",
      "15 =>> text prep output:\n",
      " ['repeat', 'certain', 'behavior', 'have', 'unusual', 'behavior', 'example', 'repeat', 'word', 'phrase', 'behavior', 'call', 'echolalia']\n",
      "15 =>> my spacy  output:\n",
      " ['repeat', 'behavior', 'unusual', 'behavior', 'repeat', 'phrase', 'behavior', 'call', 'echolalia']\n",
      "\n",
      "16 Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n",
      "16 =>> text prep output:\n",
      " ['have', 'lasting', 'intense', 'interest', 'certain', 'topic', 'number', 'detail', 'fact']\n",
      "16 =>> my spacy  output:\n",
      " ['last', 'intense', 'topic', 'detail']\n",
      "\n",
      "17 Having overly focused interests, such as with moving objects or parts of objects.\n",
      "17 =>> text prep output:\n",
      " ['have', 'overly', 'focused', 'interest', 'move', 'object', 'part', 'object']\n",
      "17 =>> my spacy  output:\n",
      " ['overly', 'focus', 'move', 'object', 'object']\n",
      "\n",
      "18 Getting upset by slight changes in a routine.\n",
      "18 =>> text prep output:\n",
      " ['get', 'upset', 'slight', 'change', 'routine']\n",
      "18 =>> my spacy  output:\n",
      " ['upset', 'slight', 'routine']\n",
      "\n",
      "19 Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n",
      "19 =>> text prep output:\n",
      " ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n",
      "19 =>> my spacy  output:\n",
      " ['sensitive', 'people', 'sensory', 'input', 'light', 'noise', 'clothing', 'temperature']\n",
      "\n",
      "20 People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n",
      "20 =>> text prep output:\n",
      " ['People', 'ASD', 'experience', 'sleep', 'problem', 'irritability', 'people', 'ASD', 'experience', 'challenge', 'strength', 'include']\n",
      "20 =>> my spacy  output:\n",
      " ['people', 'asd', 'experience', 'sleep', 'irritability', 'people', 'asd', 'experience', 'challenge', 'strength', 'include', ':']\n",
      "\n",
      "21 Being able to learn things in detail and remember information for long periods of time.\n",
      "21 =>> text prep output:\n",
      " ['able', 'learn', 'thing', 'detail', 'remember', 'information', 'long', 'period', 'time']\n",
      "21 =>> my spacy  output:\n",
      " ['learn', 'detail', 'remember', 'period', 'time']\n",
      "\n",
      "22 Being strong visual and auditory learners.\n",
      "22 =>> text prep output:\n",
      " ['strong', 'visual', 'auditory', 'learner']\n",
      "22 =>> my spacy  output:\n",
      " ['strong', 'visual', 'auditory', 'learner']\n",
      "\n",
      "23 Excelling in math, science, music, or art.\n",
      "23 =>> text prep output:\n",
      " ['excel', 'math', 'science', 'music', 'art']\n",
      "23 =>> my spacy  output:\n",
      " ['excel', 'math', 'science', 'music', 'art']\n",
      "\n",
      "24 What should I do if I got diagnosis the Autistic Spectrum Disorder?\n",
      "24 =>> text prep output:\n",
      " ['get', 'diagnosis', 'Autistic', 'Spectrum', 'disorder']\n",
      "24 =>> my spacy  output:\n",
      " ['diagnosis', 'autistic', 'spectrum', 'disorder']\n",
      "\n",
      "25 Consult a doctor and psychologist for early intervention programs.\n",
      "25 =>> text prep output:\n",
      " ['consult', 'doctor', 'psychologist', 'early', 'intervention', 'program']\n",
      "25 =>> my spacy  output:\n",
      " ['consult', 'doctor', 'psychologist', 'intervention', 'program']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Similarly, call my_preprocessing to process all the text data and\n",
    "# see what's the difference between the two functions\n",
    "with open('./questionbase_raw.txt') as file:\n",
    "    raw_sentences = [sentence.replace('\\n', '') for sentence in file.readlines()]\n",
    "    preprocessed_sentences = [] # result from 'my_preprocessing'\n",
    "    given_preprocessed_sentences = [] # result by running the 'text_preprocessing'\n",
    "    \n",
    "    #########################\n",
    "    # Your code here\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if (raw_sentence == 'Q' or raw_sentence == 'A'):\n",
    "            continue\n",
    "        else:\n",
    "            preprocessed_sentences.append(my_preprocessing(raw_sentence, spacy.load('en_core_web_sm')))\n",
    "            given_preprocessed_sentences.append(text_preprocessing(raw_sentence))\n",
    "    #########################\n",
    "    \n",
    "    i = 1\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if raw_sentence == 'Q' or raw_sentence == 'A':\n",
    "            continue\n",
    "        else:\n",
    "            print(i, raw_sentence)\n",
    "            print(i, '=>> text prep output:\\n', preprocessed_sentences[i-1])\n",
    "            print(i, '=>> my spacy  output:\\n', given_preprocessed_sentences[i-1])\n",
    "            i += 1\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the two results and explain which one is better and why?\n",
    "# Provide your answer here\n",
    "# Chang Siang's Answer:\n",
    "# It seems like the model using Spacy's library performs better than the text_processing model that was constructed by hand\n",
    "# Spacy NLP model were able to capture the context of certain words like \"United States\", while the text_preprocessing dropped the word \"state\", resulting on loss of meaning.\n",
    "# Furthermore, certain words like \"get\", \"have\", \"make\", \"able\" which provides context to the sentence meaning were preserve when using spacy model, and was dropped as \"stop word\" in text_preprocessing model.\n",
    "# Taken together, my judgement is Spacy is a better library to use for nlp preprocessing over nltk library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`The end is called a new start.` --- ISS: **I** **S**(elf) **S**(tudy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
